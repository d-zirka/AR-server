import os
import base64
import logging
from typing import Optional, List
from urllib.parse import urljoin, urlparse
from itertools import product

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

import dropbox
from dropbox.files import WriteMode

from flask import Flask, request, jsonify, url_for, redirect, send_from_directory
from bs4 import BeautifulSoup
from werkzeug.exceptions import HTTPException

# -----------------------------------------------------------------------------
# Flask app & logging
# -----------------------------------------------------------------------------
app = Flask(__name__)

# –ë—ñ–ª—å—à —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ñ –ª–æ–≥–∏
logging.basicConfig(level=logging.INFO)
app.logger.setLevel(logging.INFO)

# -----------------------------------------------------------------------------
# HTTP session –∑ —Ç–∞–π–º–∞—É—Ç–∞–º–∏ —Ç–∞ —Ä–µ—Ç—Ä–∞—è–º–∏
# -----------------------------------------------------------------------------
DEFAULT_TIMEOUT = 30

def _requests_session() -> requests.Session:
    s = requests.Session()
    s.headers.update({"User-Agent": "AR-server/1.1"})
    retries = Retry(
        total=3,
        backoff_factor=0.5,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=frozenset(["GET", "POST", "HEAD", "OPTIONS"])
    )
    s.mount("http://", HTTPAdapter(max_retries=retries))
    s.mount("https://", HTTPAdapter(max_retries=retries))
    return s

session = _requests_session()

# -----------------------------------------------------------------------------
# –ú–∞—Ä—à—Ä—É—Ç–∏ —Å–ª—É–∂–±–æ–≤—ñ
# -----------------------------------------------------------------------------
@app.route("/healthz")
def healthz():
    return "ok", 200

@app.route("/favicon.ico")
def favicon():
    # –Ø–∫—â–æ —î —Å—Ç–∞—Ç–∏—á–Ω–∏–π —Ñ–∞–π–ª ‚Äî –≤—ñ–¥–¥–∞–º–æ –π–æ–≥–æ
    static_path = os.path.join(app.root_path, "static")
    fav = os.path.join(static_path, "favicon.png")
    if os.path.exists(fav):
        return send_from_directory(static_path, "favicon.png", mimetype="image/png")
    # –Ü–Ω–∞–∫—à–µ ‚Äî –Ω–µ —à—É–º–∏–º–æ 404 —É –ª–æ–≥–∞—Ö
    return "", 204

# -----------------------------------------------------------------------------
# –ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞
# -----------------------------------------------------------------------------
@app.route("/")
def index():
    icon = url_for('static', filename='favicon.png')
    return f"""
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Canadian AR Server</title>
  <link rel="icon" href="{icon}" type="image/png">
  <style>
    body {{ font-family: sans-serif; padding: 2rem; line-height: 1.4; }}
    h1 {{ font-size: 2.2em; margin-bottom: .5em; }}
    pre {{ font-size: 1.05em; white-space: pre-wrap; }}
    .muted {{ color:#666; }}
  </style>
</head>
<body>
  <h1>Canadian AR Server is running! üöÄ</h1>
  <pre>
Functionality:
‚Ä¢ Download AR PDFs for Quebec (GM#) and Ontario
‚Ä¢ Create report folders and files for Quebec, Ontario, New Brunswick:
    ‚Äì Copy & rename Instructions.xlsx
    ‚Äì Copy & rename Geochemistry.gdb
    ‚Äì Copy & rename DDH.gdb

API:
POST /download_gm
Body (JSON): {{
  "ar_number": "GM123456" | "20000000",
  "province": "Quebec" | "Ontario" | "New Brunswick",
  "project": "MyProjectName"
}}
  </pre>
  <p class="muted">Health: <code>/healthz</code></p>
</body>
</html>
"""

# -----------------------------------------------------------------------------
# Dropbox helpers
# -----------------------------------------------------------------------------
def get_dropbox_access_token() -> str:
    cid = os.getenv("DROPBOX_CLIENT_ID")
    csec = os.getenv("DROPBOX_CLIENT_SECRET")
    rtok = os.getenv("DROPBOX_REFRESH_TOKEN")
    if not all([cid, csec, rtok]):
        raise RuntimeError("Missing Dropbox credentials")
    auth = base64.b64encode(f"{cid}:{csec}".encode()).decode()
    resp = session.post(
        "https://api.dropbox.com/oauth2/token",
        data={"grant_type": "refresh_token", "refresh_token": rtok},
        headers={"Authorization": f"Basic {auth}"},
        timeout=DEFAULT_TIMEOUT,
    )
    resp.raise_for_status()
    return resp.json()["access_token"]

def ensure_folder(dbx: dropbox.Dropbox, path: str) -> None:
    try:
        dbx.files_get_metadata(path)
    except dropbox.exceptions.ApiError:
        dbx.files_create_folder_v2(path)

# -----------------------------------------------------------------------------
# Scrape & download helpers
# -----------------------------------------------------------------------------
def _extract_pdf_links(html: str, base: str) -> List[str]:
    """–®—É–∫–∞—î PDF-–ø–æ—Å–∏–ª–∞–Ω–Ω—è, –∫–æ—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–æ–±–ª—è—î –≤—ñ–¥–Ω–æ—Å–Ω—ñ/–∞–±—Å–æ–ª—é—Ç–Ω—ñ —à–ª—è—Ö–∏."""
    soup = BeautifulSoup(html, "html.parser")
    links = []
    for a in soup.find_all("a", href=True):
        href = a["href"].strip()
        # —è–∫—â–æ –∞–±—Å–æ–ª—é—Ç–Ω–∏–π URL —ñ —Ü–µ pdf ‚Äî –±–µ—Ä–µ–º–æ —è–∫ —î
        if href.lower().endswith(".pdf") and urlparse(href).scheme in ("http", "https"):
            links.append(href)
            continue
        # —è–∫—â–æ –≤—ñ–¥–Ω–æ—Å–Ω–∏–π —à–ª—è—Ö —ñ –∑–∞–∫—ñ–Ω—á—É—î—Ç—å—Å—è –Ω–∞ .pdf ‚Äî –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ
        if href.lower().endswith(".pdf"):
            links.append(urljoin(base, href))
    return list(dict.fromkeys(links))  # —É–Ω—ñ–∫–∞–ª—å–Ω—ñ, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø–æ—Ä—è–¥–æ–∫

def _case_variants(ext: str) -> List[str]:
    """–ì–µ–Ω–µ—Ä—É—î –≤—Å—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Ä–µ–≥—ñ—Å—Ç—Ä—É –¥–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è –±–µ–∑ –∫—Ä–∞–ø–∫–∏, –Ω–∞–ø—Ä. 'pdf' -> ['pdf','pdF',...]."""
    if not ext:
        return []
    return [''.join(p) for p in product(*[(c.lower(), c.upper()) for c in ext])]

def _try_get(url: str) -> Optional[bytes]:
    try:
        r = session.get(url, timeout=DEFAULT_TIMEOUT)
        r.raise_for_status()
        return r.content
    except requests.HTTPError:
        return None

def download_ar_generic(
    ar_number: str,
    province: str,
    project: str,
    list_page_url: str | None = None,
    base_url: str | None = None
) -> int:
    """
    1) –°—Ç–≤–æ—Ä—é—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ —ñ –∫–æ–ø—ñ—é—î —à–∞–±–ª–æ–Ω–∏:
       - Instructions.xlsx
       - Geochemistry.gdb
       - DDH.gdb
    2) –Ø–∫—â–æ list_page_url –∑–∞–¥–∞–Ω–æ ‚Äî —Å–∫—Ä–∞–ø–∏—Ç—å PDF —ñ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î —ó—Ö —É Dropbox.
    –ü–æ–≤–µ—Ä—Ç–∞—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö PDF.
    """
    token = get_dropbox_access_token()
    dbx = dropbox.Dropbox(token)

    base = f"/KENORLAND_DIGITIZING/ASSESSMENT_REPORTS/1 - NEW REPORTS/{province}/{project}/{ar_number}"
    instr = f"{base}/Instructions"
    srcdata = f"{base}/Source Data"

    # –ü–∞–ø–∫–∏
    for p in (base, instr, srcdata):
        ensure_folder(dbx, p)

    # –ö–æ–ø—ñ—é–≤–∞–Ω–Ω—è —à–∞–±–ª–æ–Ω—ñ–≤ (—è–∫—â–æ –≤–∂–µ —ñ—Å–Ω—É—é—Ç—å ‚Äî –ø—Ä–æ—Å—Ç–æ –ª–æ–≥, –ø–æ–º–∏–ª–∫—É –Ω–µ –ø—ñ–¥–Ω—ñ–º–∞—î–º–æ)
    try:
        dbx.files_copy_v2(
            "/KENORLAND_DIGITIZING/ASSESSMENT_REPORTS/_Documents/Instructions/01_Instructions.xlsx",
            f"{instr}/{ar_number}_Instructions.xlsx",
            autorename=False
        )
    except dropbox.exceptions.ApiError as e:
        app.logger.warning(f"Instructions copy failed: {e}")

    try:
        dbx.files_copy_v2(
            "/KENORLAND_DIGITIZING/ASSESSMENT_REPORTS/_Documents/Instructions/ReportID_Geochemistry.gdb",
            f"{base}/{ar_number}_Geochemistry.gdb",
            autorename=False
        )
    except dropbox.exceptions.ApiError as e:
        app.logger.warning(f"Geochemistry copy failed: {e}")

    try:
        dbx.files_copy_v2(
            "/KENORLAND_DIGITIZING/ASSESSMENT_REPORTS/_Documents/Instructions/ReportID_DDH.gdb",
            f"{base}/{ar_number}_DDH.gdb",
            autorename=False
        )
    except dropbox.exceptions.ApiError as e:
        app.logger.warning(f"DDH copy failed: {e}")

    # –Ø–∫—â–æ –Ω–µ –∑–∞–¥–∞–Ω–æ —Å—Ç–æ—Ä—ñ–Ω–∫—É ‚Äî —Ç—ñ–ª—å–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞/—à–∞–±–ª–æ–Ω–∏
    if not list_page_url:
        return 0

    # –°–∫—Ä–∞–ø —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑—ñ —Å–ø–∏—Å–∫–æ–º
    resp = session.get(list_page_url, timeout=DEFAULT_TIMEOUT)
    resp.raise_for_status()

    # 1) –°–ø–µ—Ä—à—É –±–µ—Ä–µ–º–æ –≤—Å—ñ —è–≤–Ω—ñ .pdf-–ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ
    pdf_links = _extract_pdf_links(resp.text, list_page_url)

    # 2) –Ø–∫—â–æ Ontario-–≤–∞—Ä—ñ–∞–Ω—Ç (base_url –∑–∞–¥–∞–Ω–∏–π) ‚Äî —Å–ø—Ä–æ–±—É—î–º–æ —Ç–∞–∫–æ–∂ –∫–æ–Ω—Å—Ç—Ä—É—é–≤–∞—Ç–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è
    #    –∑–∞ –ø–∞—Ç–µ—Ä–Ω–æ–º <base_url>/<ar_number>/<root>.<extVariants>
    more_links: List[str] = []
    if base_url:
        soup = BeautifulSoup(resp.text, "html.parser")
        hrefs = [a["href"].strip() for a in soup.find_all("a", href=True)]
        # –±–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ —Ç—ñ href, —â–æ –≤–∫–∞–∑—É—é—Ç—å –Ω–∞ pdf (–Ω–∞–≤—ñ—Ç—å —è–∫—â–æ —Ä–µ–≥—ñ—Å—Ç—Ä ext —ñ–Ω—à–∏–π)
        candidates = []
        for h in hrefs:
            name = os.path.basename(h)
            root, ext = os.path.splitext(name)
            if ext:
                ext_clean = ext[1:]
                if ext_clean.lower() == "pdf":
                    candidates.append(root)

        # –Ø–∫—â–æ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ –Ω–µ –±—É–ª–æ —è–≤–Ω–∏—Ö .pdf, –∞–ª–µ –±—É–ª–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –∑ —ñ–º–µ–Ω–∞–º–∏ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ —ó—Ö
        if not candidates:
            # fallback: –ø–æ–±—É–¥—É—î–º–æ –∑ –±—É–¥—å-—è–∫–∏—Ö –ø–æ—Å–∏–ª–∞–Ω—å, –¥–µ —î —ñ–º'—è —Ñ–∞–π–ª—É
            for h in hrefs:
                name = os.path.basename(h)
                root, ext = os.path.splitext(name)
                if root:
                    candidates.append(root)

        candidates = list(dict.fromkeys(candidates))
        for root in candidates:
            for v in _case_variants("pdf"):
                more_links.append(f"{base_url}/{ar_number}/{root}.{v}")

    # –û–±'—î–¥–Ω—É—î–º–æ —Ç–∞ —É–Ω—ñ–∫–∞–ª—ñ–∑—É—î–º–æ
    all_links = list(dict.fromkeys(pdf_links + more_links))

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤ Dropbox
    count = 0
    for url in all_links:
        try:
            content = _try_get(url)
            if not content:
                continue
            filename = os.path.basename(urlparse(url).path) or "file.pdf"
            dst = f"{srcdata}/{filename}"
            dbx.files_upload(content, dst, mode=WriteMode.overwrite)
            count += 1
        except Exception as e:
            app.logger.error(f"PDF upload error [{url}]: {e}")

    return count

# -----------------------------------------------------------------------------
# API: –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—ñ–≤
# -----------------------------------------------------------------------------
@app.route("/download_gm", methods=["POST"])
def download_gm():
    data = request.get_json(force=True, silent=True) or {}
    num  = str(data.get("ar_number", "")).strip()
    prov = str(data.get("province", "")).strip()
    proj = str(data.get("project", "")).strip()

    if not all([num, prov, proj]):
        return jsonify(error="Missing parameters"), 400

    try:
        if prov == "Quebec" and num.upper().startswith("GM"):
            url = f"https://gq.mines.gouv.qc.ca/documents/EXAMINE/{num}/"
            cnt = download_ar_generic(num, prov, proj, url)
        elif prov == "Ontario":
            url = f"https://www.geologyontario.mndm.gov.on.ca/mndmfiles/afri/data/records/{num}.html"
            blob = "https://prd-0420-geoontario-0000-blob-cge0eud7azhvfsf7.z01.azurefd.net/lrc-geology-documents/assessment"
            cnt = download_ar_generic(num, prov, proj, url, blob)
        elif prov == "New Brunswick":
            cnt = download_ar_generic(num, prov, proj)
        else:
            return jsonify(error="Invalid province or AR#"), 400

        msg = f"Downloaded {cnt} PDFs" if cnt > 0 else "Folders created. No PDFs downloaded."
        return jsonify(message=msg), 200

    except requests.HTTPError as he:
        app.logger.error(f"HTTP error: {he}", exc_info=True)
        return jsonify(error=str(he)), 502
    except Exception as e:
        app.logger.error(f"Unexpected error: {e}", exc_info=True)
        return jsonify(error=str(e)), 500

# -----------------------------------------------------------------------------
# –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Ö–µ–Ω–¥–ª–µ—Ä –ø–æ–º–∏–ª–æ–∫:
# - HTTPException (–≤–∫–ª—é—á–Ω–æ –∑ 404) –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —è–∫ —î
# - —Ä–µ—à—Ç—É ‚Äî 500 JSON
# -----------------------------------------------------------------------------
@app.errorhandler(Exception)
def all_errors(e):
    if isinstance(e, HTTPException):
        return e
    app.logger.error(f"Unhandled: {e}", exc_info=True)
    return jsonify(error="Internal server error"), 500

# -----------------------------------------------------------------------------
# –õ–æ–∫–∞–ª—å–Ω–∏–π –∑–∞–ø—É—Å–∫ (–Ω–∞ Render —Å—Ç–∞—Ä—Ç—É—î gunicorn)
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    port = int(os.getenv("PORT", "5000"))
    app.run(host="0.0.0.0", port=port)
